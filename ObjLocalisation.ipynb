{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/Tensorflow/local/lib/python2.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.23) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/home/mohammad/Tensorflow/local/lib/python2.7/site-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./lib/\")\n",
    "\n",
    "import VOC2012DataProvider\n",
    "import VOC2012_npz_files_writter\n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from Agent import ObjLocaliser\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records have already prepared!!!\n"
     ]
    }
   ],
   "source": [
    "#This cell reads VOC 2012 dataset and save them in .npz files for future.\n",
    "#The process of reading data and put them in prper format is time consuming so they are stored in a file.\n",
    "\n",
    "xml_path = \"../VOC2012/Annotations/*.xml\"\n",
    "destination = \"../data/\"\n",
    "\n",
    "#It splits dataset to 80% for training and 20% validation.\n",
    "if not (os.path.isfile(destination+\"test_input.npz\") or os.path.isfile(destination+\"test_target.npz\")):\n",
    "    VOC2012_npz_files_writter.writting_files(xml_path, destination, percentage=0)\n",
    "    print(\"Files are ready!!!\")\n",
    "else:\n",
    "    print(\"Records have already prepared!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = VOC2012DataProvider.PascalDataProvider('train', batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name = \"W\")\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name = \"B\")\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool(x, kernel_size, stride, name = \"pool\"):\n",
    "    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1],\n",
    "    strides=[1, stride, stride, 1], padding='SAME', name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 224*224*3], name = 'x')\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 224, 224, 3])\n",
    "tf.summary.image('input', x_image, 1)\n",
    "\n",
    "\n",
    "#First Conv layer weights and biases\n",
    "W_conv1 = weight_variable([7, 7, 3, 96]) #[filter_size, filter_size, num_input_channels, num_filters]\n",
    "b_conv1 = bias_variable([96])\n",
    "#Second conv layer weights and biases\n",
    "W_conv2 = weight_variable([5, 5, 96, 256])\n",
    "b_conv2 = bias_variable([256])\n",
    "#Third conv layer weights and biases\n",
    "W_conv3 = weight_variable([3, 3, 256, 384])\n",
    "b_conv3 = bias_variable([384])\n",
    "#Fourth conv layer weights and biases\n",
    "W_conv4 = weight_variable([3, 3, 384, 384])\n",
    "b_conv4 = bias_variable([384])\n",
    "#First fully-connected layer weights and biases\n",
    "W_fc1 = weight_variable([7*7*384, 4096])\n",
    "b_fc1 = bias_variable([4096])\n",
    "#Second fully-connected layer weights and biases\n",
    "W_fc2 = weight_variable([4096, 4096])\n",
    "b_fc2 = bias_variable([4096])\n",
    "#Output layer weights and biases\n",
    "W_fc3 = weight_variable([4096, 11])\n",
    "b_fc3 = bias_variable([11])\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope(\"conv1\"):\n",
    "    #First conv layer\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1, name = \"hconv1\") #output shape = (112,112,96)\n",
    "    #First conv layer pooling layer\n",
    "    h_pool1 = max_pool(h_conv1, 3, 2, name = \"pool1\") #output shape = (56,56,96)\n",
    "\n",
    "with tf.name_scope(\"conv2\"):    \n",
    "    #Second conv layer\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 2) + b_conv2, name = \"hconv2\") #output shape = (28, 28, 256)\n",
    "    #Second conv layer pooling layer\n",
    "    h_pool2 = max_pool(h_conv2, 3, 2, name = \"pool2\") #output shape = (14, 14, 256)\n",
    "\n",
    "with tf.name_scope(\"conv3\"):\n",
    "    #Third conv layer\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3, 1) + b_conv3, name = \"hconv3\") #output shape = (14, 14, 384)\n",
    "\n",
    "with tf.name_scope(\"conv4\"):    \n",
    "    #Fourth conv layer\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4, name = \"hconv4\") #output shape = (14, 14, 384)\n",
    "    #Fourth conv layer pooling layer\n",
    "    h_pool2 = max_pool(h_conv4, 3, 2, name = \"pool4\") #output shape = (7, 7, 384)\n",
    "\n",
    "with tf.name_scope(\"fc1\"):    \n",
    "    #First fully-connected layer\n",
    "    h_flat1 = tf.reshape(h_pool2, [-1, 7*7*384])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_flat1, W_fc1) + b_fc1, name = \"hfc1\") #(input, output) = (7*7*384, 4096)\n",
    "\n",
    "with tf.name_scope(\"fc2\"):    \n",
    "    #Second fully-connected layer\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2, name = \"hfc2\") #(input, output) = (4096, 4096)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    #Output layer\n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3, name = \"hfc3\") #(input, output) = (4096, 10)\n",
    "    Qout = tf.nn.softmax(h_fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.argmax(Qout,1)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "    nextQ = tf.placeholder(shape=[1,11],dtype=tf.float32, name = 'nextQ')\n",
    "    loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "        \n",
    "with tf.name_scope(\"train\"):\n",
    "    trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "    updateModel = trainer.minimize(loss)\n",
    "    \n",
    "summ = tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "writer = tf.summary.FileWriter(\"../report/1\")\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {\n",
    "            0: 'MOVE_RIGHT',\n",
    "            1: 'MOVE_DOWN',\n",
    "            2: 'SCALE_UP',\n",
    "            3: 'ASPECT_RATIO_UP',\n",
    "            4: 'MOVE_LEFT',\n",
    "            5: 'MOVE_UP',\n",
    "            6: 'SCALE_DOWN',\n",
    "            7: 'ASPECT_RATIO_DOWN',\n",
    "            8: 'SPLIT_HORIZONTAL',\n",
    "            9: 'SPLIT_VERTICAL',\n",
    "            10: 'PLACE_LANDMARK',\n",
    "            11: 'SKIP_REGION'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e = 0.2\n",
    "y = .99\n",
    "iList = []\n",
    "rList = []\n",
    "f = open('../report/actions.txt', 'w')\n",
    "f2 = open('../report/rewards.txt', 'w')\n",
    "\n",
    "  # python will convert \\n to os.linesep\n",
    "\n",
    "\n",
    "for input_batch, target_batch in inputs:\n",
    "    for i in range(len(input_batch)):\n",
    "        #first_obj = [target_batch[i]['xmax'][0], target_batch[i]['xmin'][0], target_batch[i]['ymax'][0], target_batch[i]['ymin'][0]]\n",
    "        PILimage = Image.frombytes(\"RGB\",(input_batch[i]['image_width'],input_batch[i]['image_height']),input_batch[i]['image'])\n",
    "        #ObjLocaliser object should be initialised with a PIL image object and a dictionary of bounding boxes\n",
    "        #dqn_agent = ObjLocaliser(PILimage, target_batch[i])\n",
    "\n",
    "        for i in range(20):\n",
    "            #rAll = 0\n",
    "\n",
    "            dqn_agent = ObjLocaliser(PILimage, target_batch[i])\n",
    "            a = [0]\n",
    "            cumulative_reward = 0\n",
    "            number_of_actions = 0\n",
    "            #j = 0\n",
    "            while a[0]!=10:\n",
    "\n",
    "                s = np.array(dqn_agent.wrapping(), dtype = 'float').reshape((1,224*224*3))\n",
    "\n",
    "                a,allQ = sess.run([predict,Qout],feed_dict={x: s})\n",
    "\n",
    "                if np.random.rand(1) < e:\n",
    "                    a[0] = np.random.randint(11, size=1)\n",
    "\n",
    "                #Get new state and reward from environment\n",
    "                r = dqn_agent.takingActions(a[0])\n",
    "                cumulative_reward = cumulative_reward + r\n",
    "                f.write(\"Action:{0}\\n\".format(actions[a[0]]))\n",
    "                number_of_actions = number_of_actions + 1\n",
    "                if r==3: print(\"image filename:{0} episode:{1} cumulative reward:{2} num of actions:{3}\".format(input_batch[i]['image_filename'] ,i, cumulative_reward, number_of_actions))\n",
    "                #print \"Action:{0}\".format(actions[a[0]])\n",
    "                #print \"Reward:{0}\".format(r)\n",
    "                #dqn_agent.drawActions()\n",
    "                #time.sleep(1)\n",
    "                s1 = np.array(dqn_agent.wrapping(), dtype = 'float').reshape((1,224*224*3))\n",
    "\n",
    "                #Obtain the Q' values by feeding the new state through our network\n",
    "                Q1 = sess.run(Qout,feed_dict={x:s1})\n",
    "\n",
    "                #Obtain maxQ' and set our target value for chosen action.\n",
    "                maxQ1 = np.max(Q1)\n",
    "                targetQ = allQ\n",
    "                targetQ[0,a[0]] = r + y*maxQ1\n",
    "\n",
    "                #Train our network using target and predicted Q values\n",
    "                _ = sess.run(updateModel,feed_dict={x:s, nextQ:targetQ})\n",
    "                #writer.add_summary(repo, j)\n",
    "\n",
    "                #rAll += r\n",
    "                #j = j + 1\n",
    "            \n",
    "            f2.write(\"image filename:{0} episode:{1} cumulative reward:{2} num of actions:{3}\".format(input_batch[i]['image_filename'] ,i, cumulative_reward, number_of_actions))\n",
    "            #print(\"image filename:{0} episode:{1} cumulative reward:{2} num of actions:{3}\".format(input_batch[i]['image_filename'] ,i, cumulative_reward, number_of_actions))\n",
    "            #iList.append(i)\n",
    "            #rList.append(cumulative_reward)\n",
    "            f.write(\"episode{0} finished***************************\\n\".format(i))\n",
    "\n",
    "f.close()\n",
    "f2.close()\n",
    "saver.save(sess, '../models/5000/single_object_lr=0.1,ep=0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to add dropout layer: https://stackoverflow.com/questions/40955223/tensorflow-python-framework-errors-invalidargumenterror-input-to-reshape-is-a-t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
