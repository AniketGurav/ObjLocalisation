{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/Tensorflow/local/lib/python2.7/site-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./lib/\")\n",
    "\n",
    "import VOC2012DataProvider\n",
    "import VOC2012_npz_files_writter\n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from Agent import ObjLocaliser\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#This cell reads VOC 2012 dataset and save them in .npz files for future.\n",
    "#The process of reading data and put them in prper format is time consuming so they are stored in a file.\n",
    "\n",
    "xml_path = \"../VOC2012/Annotations/*.xml\"\n",
    "destination = \"../data/\"\n",
    "\n",
    "#It splits dataset to 80% for training and 20% validation.\n",
    "if not (os.path.isfile(destination+\"test_input.npz\") or os.path.isfile(destination+\"test_target.npz\")):\n",
    "    VOC2012_npz_files_writter.writting_files(xml_path, destination, percentage=0)\n",
    "    print(\"Files are ready!!!\")\n",
    "else:\n",
    "    print(\"Records have already prepared!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs = VOC2012DataProvider.PascalDataProvider('train', batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name = \"W\")\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name = \"B\")\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool(x, kernel_size, stride, name = \"pool\"):\n",
    "    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1],\n",
    "    strides=[1, stride, stride, 1], padding='SAME', name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 224*224*3], name = 'x')\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 224, 224, 3])\n",
    "tf.summary.image('input', x_image, 1)\n",
    "\n",
    "\n",
    "#First Conv layer weights and biases\n",
    "W_conv1 = weight_variable([7, 7, 3, 96]) #[filter_size, filter_size, num_input_channels, num_filters]\n",
    "b_conv1 = bias_variable([96])\n",
    "#Second conv layer weights and biases\n",
    "W_conv2 = weight_variable([5, 5, 96, 256])\n",
    "b_conv2 = bias_variable([256])\n",
    "#Third conv layer weights and biases\n",
    "W_conv3 = weight_variable([3, 3, 256, 384])\n",
    "b_conv3 = bias_variable([384])\n",
    "#Fourth conv layer weights and biases\n",
    "W_conv4 = weight_variable([3, 3, 384, 384])\n",
    "b_conv4 = bias_variable([384])\n",
    "#First fully-connected layer weights and biases\n",
    "W_fc1 = weight_variable([7*7*384, 4096])\n",
    "b_fc1 = bias_variable([4096])\n",
    "#Second fully-connected layer weights and biases\n",
    "W_fc2 = weight_variable([4096, 4096])\n",
    "b_fc2 = bias_variable([4096])\n",
    "#Output layer weights and biases\n",
    "W_fc3 = weight_variable([4096, 11])\n",
    "b_fc3 = bias_variable([11])\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope(\"conv1\"):\n",
    "    #First conv layer\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1, name = \"hconv1\") #output shape = (112,112,96)\n",
    "    #First conv layer pooling layer\n",
    "    h_pool1 = max_pool(h_conv1, 3, 2, name = \"pool1\") #output shape = (56,56,96)\n",
    "    tf.summary.histogram(\"weights\", W_conv1)\n",
    "    tf.summary.histogram(\"biases\", b_conv1)\n",
    "    tf.summary.histogram(\"activations\", h_conv1)\n",
    "\n",
    "with tf.name_scope(\"conv2\"):    \n",
    "    #Second conv layer\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 2) + b_conv2, name = \"hconv2\") #output shape = (28, 28, 256)\n",
    "    #Second conv layer pooling layer\n",
    "    h_pool2 = max_pool(h_conv2, 3, 2, name = \"pool2\") #output shape = (14, 14, 256)\n",
    "    tf.summary.histogram(\"weights\", W_conv2)\n",
    "    tf.summary.histogram(\"biases\", b_conv2)\n",
    "    tf.summary.histogram(\"activations\", h_conv2)\n",
    "\n",
    "with tf.name_scope(\"conv3\"):\n",
    "    #Third conv layer\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3, 1) + b_conv3, name = \"hconv3\") #output shape = (14, 14, 384)\n",
    "    tf.summary.histogram(\"weights\", W_conv3)\n",
    "    tf.summary.histogram(\"biases\", b_conv3)\n",
    "    tf.summary.histogram(\"activations\", h_conv3)\n",
    "\n",
    "with tf.name_scope(\"conv4\"):    \n",
    "    #Fourth conv layer\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4, name = \"hconv4\") #output shape = (14, 14, 384)\n",
    "    #Fourth conv layer pooling layer\n",
    "    h_pool4 = max_pool(h_conv4, 3, 2, name = \"pool4\") #output shape = (7, 7, 384)\n",
    "    tf.summary.histogram(\"weights\", W_conv4)\n",
    "    tf.summary.histogram(\"biases\", b_conv4)\n",
    "    tf.summary.histogram(\"activations\", h_conv4)\n",
    "\n",
    "with tf.name_scope(\"fc1\"):    \n",
    "    #First fully-connected layer\n",
    "    h_flat1 = tf.reshape(h_pool4, [-1, 7*7*384])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_flat1, W_fc1) + b_fc1, name = \"hfc1\") #(input, output) = (7*7*384, 4096)\n",
    "    tf.summary.histogram(\"weights\", W_fc1)\n",
    "    tf.summary.histogram(\"biases\", b_fc1)\n",
    "    tf.summary.histogram(\"activations\", h_fc1)\n",
    "\n",
    "with tf.name_scope(\"fc2\"):    \n",
    "    #Second fully-connected layer\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2, name = \"hfc2\") #(input, output) = (4096, 4096)\n",
    "    tf.summary.histogram(\"weights\", W_fc2)\n",
    "    tf.summary.histogram(\"biases\", b_fc2)\n",
    "    tf.summary.histogram(\"activations\", h_fc2)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    #Output layer\n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3, name = \"hfc3\") #(input, output) = (4096, 10)\n",
    "    tf.summary.histogram(\"weights\", W_fc3)\n",
    "    tf.summary.histogram(\"biases\", b_fc3)\n",
    "    tf.summary.histogram(\"activations\", h_fc3)\n",
    "    Qout = tf.nn.softmax(h_fc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 224*224*6], name = 'x')\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 224, 224, 6])\n",
    "tf.summary.image('input', x_image[:,:,:,0:3], 1)\n",
    "\n",
    "\n",
    "#First Conv layer weights and biases\n",
    "W_conv1 = weight_variable([7, 7, 6, 16]) #[filter_size, filter_size, num_input_channels, num_filters]\n",
    "b_conv1 = bias_variable([16])\n",
    "\n",
    "\n",
    "#First fully-connected layer weights and biases\n",
    "W_fc1 = weight_variable([56*56*16, 2048])\n",
    "b_fc1 = bias_variable([2048])\n",
    "\n",
    "#Second fully-connected layer weights and biases \n",
    "W_fc2 = weight_variable([2048, 1024]) \n",
    "b_fc2 = bias_variable([1024])\n",
    "\n",
    "#Output layer weights and biases\n",
    "W_fc3 = weight_variable([1024, 11])\n",
    "b_fc3 = bias_variable([11])\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope(\"conv1\"):\n",
    "    #First conv layer\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1, name = \"hconv1\") #output shape = (112,112,16)\n",
    "    #First conv layer pooling layer\n",
    "    h_pool1 = max_pool(h_conv1, 3, 2, name = \"pool1\") #output shape = (56,56,16)\n",
    "    tf.summary.histogram(\"weights\", W_conv1)\n",
    "    tf.summary.histogram(\"biases\", b_conv1)\n",
    "    tf.summary.histogram(\"activations\", h_conv1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"fc1\"):    \n",
    "    #First fully-connected layer\n",
    "    h_flat1 = tf.reshape(h_pool1, [-1, 56*56*16])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_flat1, W_fc1) + b_fc1, name = \"hfc1\") #(input, output) = (7*7*70, 2048)\n",
    "    tf.summary.histogram(\"weights\", W_fc1)\n",
    "    tf.summary.histogram(\"biases\", b_fc1)\n",
    "    tf.summary.histogram(\"activations\", h_fc1)\n",
    "    \n",
    "with tf.name_scope(\"fc2\"):\n",
    "\n",
    "    #Second fully-connected layer\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2, name = \"hfc2\") #(input, output) = (2048, 1024)\n",
    "    tf.summary.histogram(\"weights\", W_fc2)\n",
    "    tf.summary.histogram(\"biases\", b_fc2)\n",
    "    tf.summary.histogram(\"activations\", h_fc2)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    #Output layer\n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3, name = \"hfc3\") #(input, output) = (1024, 10)\n",
    "    tf.summary.histogram(\"weights\", W_fc3)\n",
    "    tf.summary.histogram(\"biases\", b_fc3)\n",
    "    tf.summary.histogram(\"activations\", h_fc3)\n",
    "    Qout = tf.nn.softmax(h_fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 224*224*3], name = 'x')\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 224, 224, 3])\n",
    "tf.summary.image('input', x_image, 1)\n",
    "\n",
    "\n",
    "#First Conv layer weights and biases\n",
    "W_conv1 = weight_variable([7, 7, 3, 16]) #[filter_size, filter_size, num_input_channels, num_filters]\n",
    "b_conv1 = bias_variable([16])\n",
    "#Second conv layer weights and biases\n",
    "W_conv2 = weight_variable([5, 5, 16, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "#First fully-connected layer weights and biases\n",
    "W_fc1 = weight_variable([14*14*36, 2048])\n",
    "b_fc1 = bias_variable([2048])\n",
    "\n",
    "#Second fully-connected layer weights and biases \n",
    "W_fc2 = weight_variable([2048, 1024]) \n",
    "b_fc2 = bias_variable([1024])\n",
    "\n",
    "#Output layer weights and biases\n",
    "W_fc3 = weight_variable([1024, 11])\n",
    "b_fc3 = bias_variable([11])\n",
    "\n",
    "\n",
    "\n",
    "with tf.name_scope(\"conv1\"):\n",
    "    #First conv layer\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1, name = \"hconv1\") #output shape = (112,112,16)\n",
    "    #First conv layer pooling layer\n",
    "    h_pool1 = max_pool(h_conv1, 3, 2, name = \"pool1\") #output shape = (56,56,16)\n",
    "    tf.summary.histogram(\"weights\", W_conv1)\n",
    "    tf.summary.histogram(\"biases\", b_conv1)\n",
    "    tf.summary.histogram(\"activations\", h_conv1)\n",
    "\n",
    "with tf.name_scope(\"conv2\"):    \n",
    "    #Second conv layer\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 2) + b_conv2, name = \"hconv2\") #output shape = (28, 28, 36)\n",
    "    #Second conv layer pooling layer\n",
    "    h_pool2 = max_pool(h_conv2, 3, 2, name = \"pool2\") #output shape = (14, 14, 36)\n",
    "    tf.summary.histogram(\"weights\", W_conv2)\n",
    "    tf.summary.histogram(\"biases\", b_conv2)\n",
    "    tf.summary.histogram(\"activations\", h_conv2)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"fc1\"):    \n",
    "    #First fully-connected layer\n",
    "    h_flat1 = tf.reshape(h_pool2, [-1, 14*14*36])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_flat1, W_fc1) + b_fc1, name = \"hfc1\") #(input, output) = (7*7*70, 2048)\n",
    "    tf.summary.histogram(\"weights\", W_fc1)\n",
    "    tf.summary.histogram(\"biases\", b_fc1)\n",
    "    tf.summary.histogram(\"activations\", h_fc1)\n",
    "    \n",
    "with tf.name_scope(\"fc2\"):\n",
    "\n",
    "    #Second fully-connected layer\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2, name = \"hfc2\") #(input, output) = (2048, 1024)\n",
    "    tf.summary.histogram(\"weights\", W_fc2)\n",
    "    tf.summary.histogram(\"biases\", b_fc2)\n",
    "    tf.summary.histogram(\"activations\", h_fc2)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    #Output layer\n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3, name = \"hfc3\") #(input, output) = (1024, 10)\n",
    "    tf.summary.histogram(\"weights\", W_fc3)\n",
    "    tf.summary.histogram(\"biases\", b_fc3)\n",
    "    tf.summary.histogram(\"activations\", h_fc3)\n",
    "    Qout = tf.nn.softmax(h_fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.argmax(Qout,1)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "    nextQ = tf.placeholder(shape=[1,11],dtype=tf.float32, name = 'nextQ')\n",
    "    loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "        \n",
    "with tf.name_scope(\"train\"):\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    updateModel = trainer.minimize(loss)\n",
    "    \n",
    "summ = tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "writer = tf.summary.FileWriter(\"../report/test\")\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {\n",
    "            0: 'MOVE_RIGHT',\n",
    "            1: 'MOVE_DOWN',\n",
    "            2: 'SCALE_UP',\n",
    "            3: 'ASPECT_RATIO_UP',\n",
    "            4: 'MOVE_LEFT',\n",
    "            5: 'MOVE_UP',\n",
    "            6: 'SCALE_DOWN',\n",
    "            7: 'ASPECT_RATIO_DOWN',\n",
    "            8: 'SPLIT_HORIZONTAL',\n",
    "            9: 'SPLIT_VERTICAL',\n",
    "            10: 'PLACE_LANDMARK',\n",
    "            11: 'SKIP_REGION'\n",
    "        }\n",
    "\n",
    "#PILimage = Image.frombytes(\"RGB\",(inputs.inputs[0]['image_width'],inputs.inputs[0]['image_height']),inputs.inputs[0]['image'])\n",
    "\n",
    "#fake_input = np.zeros((224,224,3))\n",
    "#fake_input[87:137,87:137,:] = 1\n",
    "#fake_input = fake_input/1.0\n",
    "#print fake_input.dtype\n",
    "im2 = (Image.open('../VOC2012/JPEGImages/2010_000959.jpg'))#train\n",
    "im2 = (Image.open('../VOC2012/JPEGImages/2009_002749.jpg'))#bottle\n",
    "dqn_agent = ObjLocaliser(np.array(im2),{'xmin':[16], 'xmax':[93], 'ymin':[37], 'ymax':[432]})\n",
    "e = 0.2\n",
    "y = .9\n",
    "iList = []\n",
    "rList = []\n",
    "eList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:0 cumulative reward:-102 num of actions:174\n",
      "episode:1 cumulative reward:-30 num of actions:32\n",
      "episode:2 cumulative reward:-87 num of actions:97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#f = open('../report/actions.txt', 'w')\n",
    "  # python will convert \\n to os.linesep\n",
    "\n",
    "\n",
    "#for input_batch, target_batch in inputs:\n",
    "    \n",
    "#first_obj = [target_batch[i]['xmax'][0], target_batch[i]['xmin'][0], target_batch[i]['ymax'][0], target_batch[i]['ymin'][0]]\n",
    "#PILimage = Image.frombytes(\"RGB\",(inputs.inputs[0]['image_width'],inputs.inputs[0]['image_height']),inputs.inputs[0]['image'])\n",
    "#ObjLocaliser object should be initialised with a PIL image object and a dictionary of bounding boxes\n",
    "#dqn_agent = ObjLocaliser(PILimage, inputs.targets[0])\n",
    "\n",
    "\n",
    "#dqn_agent = ObjLocaliser(x, {'xmin':[87], 'ymin':[137],'xmax':[87], 'ymax':[137]})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#agent = ObjLocaliser(im2,{'xmin':[170], 'xmax':[220], 'ymin':[58], 'ymax':[206]})\n",
    "num_located = 0\n",
    "#saver.restore(sess, \"/home/mohammad/active localization/models/checkpoint\")\n",
    "\n",
    "for i in range(80):\n",
    "    #rAll = 0\n",
    "\n",
    "    #dqn_agent = ObjLocaliser(PILimage, inputs.targets[0])\n",
    "    #dqn_agent = ObjLocaliser(fake_input, {'xmin':[87], 'ymin':[137],'xmax':[87], 'ymax':[137]})\n",
    "    dqn_agent = ObjLocaliser(np.array(im2),{'xmin':[16], 'xmax':[93], 'ymin':[37], 'ymax':[432]})\n",
    "\n",
    "\n",
    "    a = [0,0]\n",
    "    cumulative_reward = 0\n",
    "    number_of_actions = 0\n",
    "    error = 0.\n",
    "    #j = 0\n",
    "    while a[0]!=10:\n",
    "        \n",
    "        s = np.array(dqn_agent.wrapping(), dtype = 'float').reshape((1,224*224*3))\n",
    "\n",
    "        a,allQ = sess.run([predict,Qout],feed_dict={x: s})\n",
    "\n",
    "        if np.random.rand(1) < e:\n",
    "            a[0] = np.random.randint(11, size=1)\n",
    "\n",
    "        #Get new state and reward from environment\n",
    "        r = dqn_agent.takingActions(a[0])\n",
    "        if r == 3:\n",
    "            num_located = num_located + 1\n",
    "        cumulative_reward = cumulative_reward + r\n",
    "        #f.write(\"Action:{0}\\n\".format(actions[a[0]]))\n",
    "        number_of_actions = number_of_actions + 1\n",
    "        #print \"Action:{0}\".format(actions[a[0]])\n",
    "        #print \"Reward:{0}\".format(r)\n",
    "        #dqn_agent.drawActions()\n",
    "        #time.sleep(1)\n",
    "        s1 = np.array(dqn_agent.wrapping(), dtype = 'float').reshape((1,224*224*3))\n",
    "\n",
    "        #Obtain the Q' values by feeding the new state through our network\n",
    "        Q1 = sess.run(Qout,feed_dict={x:s1})\n",
    "\n",
    "        #Obtain maxQ' and set our target value for chosen action.\n",
    "        maxQ1 = np.max(Q1)\n",
    "        targetQ = allQ\n",
    "        targetQ[0,a[0]] = r + y*maxQ1\n",
    "\n",
    "        #Train our network using target and predicted Q values\n",
    "        _, s, l = sess.run([updateModel,summ, loss],feed_dict={x:s, nextQ:targetQ})\n",
    "        writer.add_summary(s, i)\n",
    "        error = error + l\n",
    "        #print l\n",
    "        #print(\"Q:{0}  targetQ:{1}  reward:{2}\".format(allQ, targetQ, r))\n",
    "        #print targetQ-allQ\n",
    "        #writer.add_summary(repo, j)\n",
    "\n",
    "        #rAll += r\n",
    "        #j = j + 1\n",
    "        \n",
    "    print(\"episode:{0} cumulative reward:{1} num of actions:{2}\".format(i, cumulative_reward, number_of_actions))\n",
    "    iList.append(i)\n",
    "    rList.append(float(cumulative_reward)/number_of_actions)\n",
    "    eList.append(float(error)/number_of_actions)\n",
    "    \n",
    "    #f.write(\"episode{0} finished***************************\\n\".format(i))\n",
    "        \n",
    "#f.close()\n",
    "#saver.save(sess, '../models/single_object_bottle_image.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print num_located\n",
    "plt.plot(rList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eList)\n",
    "#plt.savefig(\"./report/test/error_single_object_bottle_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e = 0.1\n",
    "y = .99\n",
    "jList = []\n",
    "rList = []\n",
    "\n",
    "for input_batch, target_batch in inputs:\n",
    "    for i in range(len(input_batch)):\n",
    "        rAll = 0\n",
    "        #first_obj = [target_batch[i]['xmax'][0], target_batch[i]['xmin'][0], target_batch[i]['ymax'][0], target_batch[i]['ymin'][0]]\n",
    "        PILimage = Image.frombytes(\"RGB\",(inputs.inputs[i]['image_width'],inputs.inputs[i]['image_height']),inputs.inputs[i]['image'])\n",
    "        #ObjLocaliser object should be initialised with a PIL image object and a dictionary of bounding boxes\n",
    "        dqn_agent = ObjLocaliser(PILimage, target_batch[i])\n",
    "\n",
    "        for j in range(50):\n",
    "            \n",
    "            s = np.array(dqn_agent.wrapping(), dtype = 'float').reshape((1,224*224*3))\n",
    "            \n",
    "            a,allQ = sess.run([predict,Qout],feed_dict={x: s})\n",
    "            \n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = np.random.randint(11, size=1)\n",
    "                \n",
    "            #Get new state and reward from environment\n",
    "            r = dqn_agent.takingActions(a[0])\n",
    "            print \"Action:{0}\".format(actions[a[0]])\n",
    "            print \"Reward:{0}\".format(r)\n",
    "            #dqn_agent.drawActions()\n",
    "            #time.sleep(1)\n",
    "            s1 = np.array(dqn_agent.wrapping(), dtype = 'float').reshape((1,224*224*3))\n",
    "            \n",
    "            #Obtain the Q' values by feeding the new state through our network\n",
    "            Q1 = sess.run(Qout,feed_dict={x:s1})\n",
    "            \n",
    "            #Obtain maxQ' and set our target value for chosen action.\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0,a[0]] = r + y*maxQ1\n",
    "            \n",
    "            #Train our network using target and predicted Q values\n",
    "            _ = sess.run(updateModel,feed_dict={x:s, nextQ:targetQ})\n",
    "            #writer.add_summary(repo, j)\n",
    "            \n",
    "            rAll += r\n",
    "            jList.append(j)\n",
    "            rList.append(rAll)\n",
    "            \n",
    "            \n",
    "        print \"Overall reward in episode:{0}\".format(rAll)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restoring saved models: http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a=sess.graph.get_operation_by_name('fc3')\n",
    "a.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to add dropout layer: https://stackoverflow.com/questions/40955223/tensorflow-python-framework-errors-invalidargumenterror-input-to-reshape-is-a-t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
